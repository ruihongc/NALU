{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# iNALU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EI57uiwQ1ryW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Layers and Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# original NALU with matrix gates\n",
        "class NALU_Matrix(tf.keras.layers.Layer):\n",
        "  def __init__(self, in_features=2, out_units=1, epsilon=0.000001):\n",
        "    super().__init__()\n",
        "    self.in_features = in_features\n",
        "    self.out_units = out_units\n",
        "    self.epsilon = epsilon\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    self.G = self.add_weight(name=\"Gate_weights\",\n",
        "                             shape=[self.in_features, self.out_units],\n",
        "                             initializer=tf.random_normal_initializer(stddev=1.0),\n",
        "                             trainable=True)\n",
        "    self.AW_hat = self.add_weight(name=\"AW_hat\",\n",
        "                                  shape=[self.in_features, self.out_units],\n",
        "                                  initializer=tf.initializers.random_uniform(minval=-2, maxval=2),\n",
        "                                  trainable=True)\n",
        "    self.AM_hat = self.add_weight(name=\"AM_hat\",\n",
        "                                  shape=[self.in_features, self.out_units],\n",
        "                                  initializer=tf.initializers.random_uniform(minval=-2, maxval=2),\n",
        "                                  trainable=True)\n",
        "    self.MW_hat = self.add_weight(name=\"MW_hat\",\n",
        "                                  shape=[self.in_features, self.out_units],\n",
        "                                  initializer=tf.initializers.random_uniform(minval=-2, maxval=2),\n",
        "                                  trainable=True)\n",
        "    self.MM_hat = self.add_weight(name=\"MM_hat\",\n",
        "                                  shape=[self.in_features, self.out_units],\n",
        "                                  initializer=tf.initializers.random_uniform(minval=-2, maxval=2),\n",
        "                                  trainable=True)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    a = tf.matmul(inputs, tf.nn.tanh(self.AW_hat) * tf.nn.sigmoid(self.AM_hat))\n",
        "    m = tf.exp(tf.matmul(tf.math.log(tf.abs(inputs) + self.epsilon), tf.nn.tanh(self.MW_hat) * tf.nn.sigmoid(self.MM_hat)))\n",
        "    gT = tf.nn.sigmoid( tf.matmul(inputs, self.G) )\n",
        "    return tf.multiply(gT, a) + tf.multiply(1 - gT, m)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# original NALU with vector gates\n",
        "class NALU_Vector(tf.keras.layers.Layer):\n",
        "  def __init__(self, in_features=2, out_units=1, epsilon=0.000001):\n",
        "    super().__init__()\n",
        "    self.in_features = in_features\n",
        "    self.out_units = out_units\n",
        "    self.epsilon = epsilon\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    self.G = self.add_weight(name=\"Gate_weights\",\n",
        "                             shape=[self.in_features],\n",
        "                             initializer=tf.random_normal_initializer(stddev=1.0),\n",
        "                             trainable=True)\n",
        "    self.AW_hat = self.add_weight(name=\"AW_hat\",\n",
        "                                  shape=[self.out_units, self.in_features],\n",
        "                                  initializer=tf.initializers.random_uniform(minval=-2, maxval=2),\n",
        "                                  trainable=True)\n",
        "    self.AM_hat = self.add_weight(name=\"AM_hat\",\n",
        "                                  shape=[self.out_units, self.in_features],\n",
        "                                  initializer=tf.initializers.random_uniform(minval=-2, maxval=2),\n",
        "                                  trainable=True)\n",
        "    self.MW_hat = self.add_weight(name=\"MW_hat\",\n",
        "                                  shape=[self.out_units, self.in_features],\n",
        "                                  initializer=tf.initializers.random_uniform(minval=-2, maxval=2),\n",
        "                                  trainable=True)\n",
        "    self.MM_hat = self.add_weight(name=\"MM_hat\",\n",
        "                                  shape=[self.out_units, self.in_features],\n",
        "                                  initializer=tf.initializers.random_uniform(minval=-2, maxval=2),\n",
        "                                  trainable=True)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    a = tf.matmul(inputs, tf.nn.tanh(self.AW_hat) * tf.nn.sigmoid(self.AM_hat), transpose_b=True)\n",
        "    m = tf.exp(tf.matmul(tf.math.log(tf.abs(inputs) + self.epsilon), tf.nn.tanh(self.MW_hat) * tf.nn.sigmoid(self.MM_hat), transpose_b=True))\n",
        "    gT = tf.sigmoid(tf.matmul(inputs, tf.reshape(self.G, [self.in_features, -1])))\n",
        "    return tf.multiply(gT, a) + tf.multiply(1 - gT, m)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# improved NALU with matrix gates\n",
        "class iNALU_Matrix(tf.keras.layers.Layer):\n",
        "  def __init__(self, in_features=2, out_units=1, epsilon=0.000001, clipping=20):\n",
        "    super().__init__()\n",
        "    self.in_features = in_features\n",
        "    self.out_units = out_units\n",
        "    self.epsilon = epsilon\n",
        "    self.clipping = clipping\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    self.G = self.add_weight(name=\"Gate_weights\",\n",
        "                             shape=[self.in_features, self.out_units],\n",
        "                             initializer=tf.random_normal_initializer(stddev=1.0),\n",
        "                             trainable=True)\n",
        "    self.AW_hat = self.add_weight(name=\"AW_hat\",\n",
        "                                  shape=[self.in_features, self.out_units],\n",
        "                                  initializer=tf.initializers.random_uniform(minval=-2, maxval=2),\n",
        "                                  trainable=True)\n",
        "    self.AM_hat = self.add_weight(name=\"AM_hat\",\n",
        "                                  shape=[self.in_features, self.out_units],\n",
        "                                  initializer=tf.initializers.random_uniform(minval=-2, maxval=2),\n",
        "                                  trainable=True)\n",
        "    self.MW_hat = self.add_weight(name=\"MW_hat\",\n",
        "                                  shape=[self.in_features, self.out_units],\n",
        "                                  initializer=tf.initializers.random_uniform(minval=-2, maxval=2),\n",
        "                                  trainable=True)\n",
        "    self.MM_hat = self.add_weight(name=\"MM_hat\",\n",
        "                                  shape=[self.in_features, self.out_units],\n",
        "                                  initializer=tf.initializers.random_uniform(minval=-2, maxval=2),\n",
        "                                  trainable=True)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    a = tf.matmul(inputs, tf.nn.tanh(self.AW_hat) * tf.nn.sigmoid(self.AM_hat))\n",
        "    w = tf.nn.tanh(self.MW_hat) * tf.nn.sigmoid(self.MM_hat)\n",
        "    m = tf.exp(tf.minimum(tf.matmul(tf.math.log(tf.maximum(tf.abs(inputs), self.epsilon)), w), self.clipping))\n",
        "    g = tf.sigmoid(tf.matmul(tf.abs(inputs), self.G))\n",
        "    s = tf.abs(tf.reshape(w, [-1])) # flatten s to (200)\n",
        "    return g * a + (1 - g) * m * tf.clip_by_value(tf.reduce_prod(tf.reshape(tf.sign(tf.reshape(tf.concat([inputs] * w.shape[1], axis=1), shape=[-1, w.shape[0] * w.shape[1]])) * s + (1 - s), shape=[-1, w.shape[1], w.shape[0]]), axis=2), -1, 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# improved NALU with vector gates\n",
        "class iNALU_Vector(tf.keras.layers.Layer):\n",
        "  def __init__(self, in_features=2, out_units=1, epsilon=0.000001, clipping=20):\n",
        "    super().__init__()\n",
        "    self.in_features = in_features\n",
        "    self.out_units = out_units\n",
        "    self.epsilon = epsilon\n",
        "    self.clipping = clipping\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    self.G = self.add_weight(name=\"Gate_weights\",\n",
        "                             shape=[self.in_features],\n",
        "                             initializer=tf.random_normal_initializer(stddev=1.0),\n",
        "                             trainable=True)\n",
        "    self.AW_hat = self.add_weight(name=\"AW_hat\",\n",
        "                                  shape=[self.out_units, self.in_features],\n",
        "                                  initializer=tf.initializers.random_uniform(minval=-2, maxval=2),\n",
        "                                  trainable=True)\n",
        "    self.AM_hat = self.add_weight(name=\"AM_hat\",\n",
        "                                  shape=[self.out_units, self.in_features],\n",
        "                                  initializer=tf.initializers.random_uniform(minval=-2, maxval=2),\n",
        "                                  trainable=True)\n",
        "    self.MW_hat = self.add_weight(name=\"MW_hat\",\n",
        "                                  shape=[self.out_units, self.in_features],\n",
        "                                  initializer=tf.initializers.random_uniform(minval=-2, maxval=2),\n",
        "                                  trainable=True)\n",
        "    self.MM_hat = self.add_weight(name=\"MM_hat\",\n",
        "                                  shape=[self.out_units, self.in_features],\n",
        "                                  initializer=tf.initializers.random_uniform(minval=-2, maxval=2),\n",
        "                                  trainable=True)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    a = tf.matmul(inputs, tf.nn.tanh(self.AW_hat) * tf.nn.sigmoid(self.AM_hat), transpose_b=True)\n",
        "    w = tf.transpose(tf.nn.tanh(self.MW_hat) * tf.nn.sigmoid(self.MM_hat))\n",
        "    m = tf.exp(tf.minimum(tf.matmul(tf.math.log(tf.abs(inputs) + self.epsilon), w), self.clipping))\n",
        "    g = tf.sigmoid(tf.matmul(tf.abs(inputs), tf.reshape(self.G, [self.in_features, -1])))\n",
        "    s = tf.abs(tf.reshape(w, [-1])) # flatten s to (200)\n",
        "    return g * a + (1 - g) * m * tf.clip_by_value(tf.reduce_prod(tf.reshape(tf.sign(tf.reshape(tf.concat([inputs] * w.shape[1], axis=1), shape=[-1, w.shape[0] * w.shape[1]])) * s + (1 - s), shape=[-1, w.shape[1], w.shape[0]]), axis=2), -1, 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# improved NALU with input-independent gates\n",
        "class iNALU_Independent(tf.keras.layers.Layer):\n",
        "  def __init__(self, in_features=2, out_units=1, epsilon=0.000001, clipping=20):\n",
        "    super().__init__()\n",
        "    self.in_features = in_features\n",
        "    self.out_units = out_units\n",
        "    self.epsilon = epsilon\n",
        "    self.clipping = clipping\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    self.G = self.add_weight(name=\"Gate_weights\",\n",
        "                             shape=[self.out_units],\n",
        "                             initializer=tf.random_normal_initializer(stddev=1.0),\n",
        "                             trainable=True)\n",
        "    self.AW_hat = self.add_weight(name=\"AW_hat\",\n",
        "                                  shape=[self.in_features, self.out_units],\n",
        "                                  initializer=tf.initializers.random_uniform(minval=-2, maxval=2),\n",
        "                                  trainable=True)\n",
        "    self.AM_hat = self.add_weight(name=\"AM_hat\",\n",
        "                                  shape=[self.in_features, self.out_units],\n",
        "                                  initializer=tf.initializers.random_uniform(minval=-2, maxval=2),\n",
        "                                  trainable=True)\n",
        "    self.MW_hat = self.add_weight(name=\"MW_hat\",\n",
        "                                  shape=[self.in_features, self.out_units],\n",
        "                                  initializer=tf.initializers.random_uniform(minval=-2, maxval=2),\n",
        "                                  trainable=True)\n",
        "    self.MM_hat = self.add_weight(name=\"MM_hat\",\n",
        "                                  shape=[self.in_features, self.out_units],\n",
        "                                  initializer=tf.initializers.random_uniform(minval=-2, maxval=2),\n",
        "                                  trainable=True)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    a = tf.matmul(inputs, tf.nn.tanh(self.AW_hat) * tf.nn.sigmoid(self.AM_hat))\n",
        "    w = tf.nn.tanh(self.MW_hat) * tf.nn.sigmoid(self.MM_hat)\n",
        "    m = tf.exp(tf.minimum(tf.matmul(tf.math.log(tf.maximum(tf.abs(inputs), self.epsilon)), w), self.clipping))\n",
        "    g = tf.sigmoid(self.G)\n",
        "    s = tf.abs(tf.reshape(w, [-1])) # flatten s to (200)\n",
        "    return g * a + (1 - g) * m * tf.clip_by_value(tf.reduce_prod(tf.reshape(tf.sign(tf.reshape(tf.concat([inputs] * w.shape[1], axis=1), shape=[-1, w.shape[0] * w.shape[1]])) * s + (1 - s), shape=[-1, w.shape[1], w.shape[0]]), axis=2), -1, 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# create a sequential NALU model of one of the NALU architectures\n",
        "# model depth = len(dims) - 1\n",
        "# dims[0] = input shape\n",
        "# dims[-1] = output shape\n",
        "def Sequential_NALU(arch, dims):\n",
        "  return tf.keras.Sequential([tf.keras.Input(shape=dims[0])] + [\n",
        "      arch(dims[i-1], dims[i]) for i in range(1, len(dims))\n",
        "  ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OM3qZAdqSU3Q"
      },
      "outputs": [],
      "source": [
        "my_function = lambda inputs: ( # wrapper\n",
        "  lambda x1, x2, x3: x1 * x2 + x3 # formula\n",
        ")(*inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxTZxDN518xc",
        "outputId": "b6af4cde-d880-4cc6-ecb4-c2fbad951cfc"
      },
      "outputs": [],
      "source": [
        "def train_gen(formula, starts: list, steps: list, num_values: int, num_samples: int):\n",
        "  # Generate a range of numbers at regular intervals for training\n",
        "  x_t = np.array([np.arange(starts[i], starts[i] + num_samples*steps[i], step=steps[i], dtype=np.float32) for i in range(num_values)])\n",
        "  y_t = formula(x_t)\n",
        "\n",
        "  return x_t.T, y_t\n",
        "\n",
        "x_train, y_train = train_gen(\n",
        "  my_function,\n",
        "  [0, 5, 1000],\n",
        "  [1, 1, 1024],\n",
        "  3,\n",
        "  1000,\n",
        ")\n",
        "\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dcf-uhbER4kw",
        "outputId": "4467af58-4153-4810-fa74-0804e462e9c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(200, 3)\n",
            "(200,)\n"
          ]
        }
      ],
      "source": [
        "def test_gen(formula, min: int, max: int, num_values: int, num_samples: int):\n",
        "  # Generate a series of input numbers for testing\n",
        "  x_t = np.random.randint(min, max, size=(num_samples, num_values,)).astype(np.float32)\n",
        "  y_t = formula(x_t.T)\n",
        "\n",
        "  return x_t, y_t\n",
        "\n",
        "x_test, y_test = test_gen(\n",
        "  my_function,\n",
        "  0,\n",
        "  10000,\n",
        "  3,\n",
        "  200,\n",
        ")\n",
        "\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# inputs = tf.keras.Input(shape=(x_train.shape[1],))\n",
        "# outputs = NALU_Matrix(x_train.shape[1], x_train.shape[1])(inputs)\n",
        "# model = tf.keras.Model(inputs=inputs, outputs=outputs,)\n",
        "model = Sequential_NALU(\n",
        "    iNALU_Independent,\n",
        "    [x_train.shape[1], x_train.shape[1], 1]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RVPvxh8uNGe3"
      },
      "outputs": [],
      "source": [
        "loss_fn = tf.keras.losses.MeanSquaredError()\n",
        "\n",
        "starter_learning_rate = 0.01\n",
        "end_learning_rate = 0.0001\n",
        "epochs = 50000\n",
        "epsilon = 1e-06\n",
        "decay_steps = 0.9 * epochs\n",
        "alpha = tf.keras.optimizers.schedules.PolynomialDecay(\n",
        "    starter_learning_rate,\n",
        "    decay_steps,\n",
        "    end_learning_rate,\n",
        "    power=0.5)\n",
        "\n",
        "optimizer = tf.keras.optimizers.experimental.RMSprop(\n",
        "    learning_rate=alpha,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "earlystopping = tf.keras.callbacks.EarlyStopping(monitor='mse', patience=5000,) # min_delta=epsilon)\n",
        "\n",
        "checkpoint_filepath = '/tmp/checkpoint'\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True,\n",
        "    monitor='mse',\n",
        "    save_best_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QSSrrsVfmKIi"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=optimizer,\n",
        "              loss=loss_fn,\n",
        "              metrics=[tf.keras.metrics.MeanAbsoluteError(name='mae'), tf.keras.metrics.MeanSquaredError(name='mse'), tf.keras.metrics.MeanAbsolutePercentageError(name='mape'), tf.keras.metrics.MeanSquaredLogarithmicError(name='msle')],)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbG0_kDKP1YW",
        "outputId": "bf3be8cf-6e68-4a6b-ed05-93b6802a4dbf"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvPEV3rZj4Dd",
        "outputId": "6b27db2c-a06a-41f1-9e0a-c55a90e49505"
      },
      "outputs": [],
      "source": [
        "history = model.fit(x_train,\n",
        "                    y_train,\n",
        "                    epochs=epochs,\n",
        "                    # callbacks=[earlystopping],\n",
        "                    callbacks=[model_checkpoint_callback],\n",
        "                    verbose=1,)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluation and Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DILHeUyinRQe",
        "outputId": "2512366a-804c-4523-86e7-2cfa05c01de9"
      },
      "outputs": [],
      "source": [
        "# Automated evaluation on main test set\n",
        "model.evaluate(x_test,  y_test, verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ylgd7LxmSe8"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model on a test set and pretty print\n",
        "def pretty_test(model, x_test, y_test, template, final, epsilon=1e-9):\n",
        "  assert len(x_test) == len(y_test)\n",
        "  lines = []\n",
        "  perc = 0\n",
        "  total = len(y_test)\n",
        "  rms = []\n",
        "  for i in range(total):\n",
        "    x = x_test[i]\n",
        "    y = y_test[i]\n",
        "    pred = model.predict(np.expand_dims(x, axis=0), verbose=0).squeeze().squeeze()\n",
        "    acc = np.abs(pred/y) if np.abs(pred) < np.abs(y) else np.abs(y/pred)\n",
        "    perc += acc\n",
        "    err = np.abs(pred - y)\n",
        "    rms.append(err)\n",
        "    lines.append(template.format(*x, y, pred, acc, err))\n",
        "  acc = perc/total\n",
        "  rms = np.sqrt(np.mean(np.array(rms)**2))\n",
        "  lines.append(final.format(acc, rms))\n",
        "  return lines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dA7RleiuB-tx",
        "outputId": "4ed77052-d65a-486b-859d-f3084f859daf"
      },
      "outputs": [],
      "source": [
        "# Manual human readable testing\n",
        "x_test_2, y_test_2 = test_gen(\n",
        "  my_function,\n",
        "  50,\n",
        "  100,\n",
        "  3,\n",
        "  10,\n",
        ")\n",
        "\n",
        "print(\"\\n\".join(pretty_test(\n",
        "  model,\n",
        "  x_test_2,\n",
        "  y_test_2,\n",
        "  \"({} * {}) + {} = {}, prediction: {}, accuracy: {}, error: {}\",\n",
        "  \"accuracy: {}, rms: {}\",\n",
        "  epsilon,\n",
        ")))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w_d0LBQ2TMxB"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
